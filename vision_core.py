"""
Vision Core: MiniCPM-V 2.6 int4 ç”»åƒè§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
kotarou-engine è¦–è¦šèªè­˜ã‚³ã‚¢

RTX 4060 (8GB VRAM) æœ€é©åŒ–æ¸ˆã¿
- 4-bité‡å­åŒ– (ç´„7GB VRAMä½¿ç”¨)
- ç”»åƒãƒªã‚µã‚¤ã‚º (512px) ã«ã‚ˆã‚‹VRAMç¯€ç´„
- æ¨è«–å¾ŒVRAMè§£æ”¾

ä½¿ç”¨æ–¹æ³•:
    from vision_core import VisionCore
    
    vision = VisionCore()
    result = vision.analyze("path/to/image.jpg")
"""

import torch
from PIL import Image
from pathlib import Path
from typing import Optional, Dict, Any
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# =============================================================================
# è¨­å®šå€¤ï¼ˆæŒ‡ä»¤æ›¸æº–æ‹ ï¼‰
# =============================================================================

CONFIG = {
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    "model_id": "openbmb/MiniCPM-V-2_6-int4",
    
    # ç”»åƒå‰å‡¦ç†
    "max_image_size": 512,  # é•·è¾ºæœ€å¤§pxï¼ˆVRAMç¯€ç´„ï¼‰
    
    # ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šï¼ˆãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æŠ‘åˆ¶ï¼‰
    "temperature": 0.3,      # ä½æ¸©åº¦ â†’ å¿ å®Ÿåº¦å‘ä¸Š
    "top_p": 0.8,            # ç¢ºä¿¡åº¦ä½ã„æƒ…å ±ã®æ’é™¤
    "repetition_penalty": 1.2,  # ãƒ«ãƒ¼ãƒ—é˜²æ­¢
    "max_new_tokens": 512,
}

# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæŒ‡ä»¤æ›¸æº–æ‹ ï¼‰
SYSTEM_PROMPT = """ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ•ã‚©ãƒˆã‚°ãƒ©ãƒ•ã‚¡ãƒ¼å…¼ã€å„ªã‚ŒãŸè¦³å¯Ÿçœ¼ã‚’æŒã¤ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
å…¥åŠ›ã•ã‚ŒãŸç”»åƒã«å¯¾ã—ã€ä»¥ä¸‹ã®4é …ç›®ã‚’è©³ç´°ã«ã€ã‹ã¤å®¢è¦³çš„ã«æ—¥æœ¬èªã§åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
- æ¨æ¸¬ã®ç¦æ­¢: å†™ã£ã¦ã„ãªã„ã‚‚ã®ã‚’ã€ŒãŠãã‚‰ãã€œã ã‚ã†ã€ã¨è¨˜è¿°ã™ã‚‹ã“ã¨ã‚’å³ç¦ã¨ã™ã‚‹
- ä½ç…§åº¦ãƒ»ééœ²å‡ºã¸ã®å¯¾å¿œ: ç”»åƒãŒçœ©ã—ã™ãã‚‹/æš—ã™ãã‚‹å ´åˆã€ãã®çŠ¶æ…‹è‡ªä½“ã‚’ã€Œå…‰ã«åŒ…ã¾ã‚ŒãŸã€ã€Œå½±ã«æ²ˆã‚“ã ã€ã¨äº‹å®Ÿã¨ã—ã¦è¨˜è¿°ã™ã‚‹
- å‡ºåŠ›ã¯ç®‡æ¡æ›¸ãã§è¨˜è¿°ã™ã‚‹"""

USER_PROMPT = """ã“ã®å†™çœŸã‚’ä»¥ä¸‹ã®4é …ç›®ã§åˆ†æã—ã¦ãã ã•ã„ï¼š

â–  ä¸»å½¹ã®è¦ç´ 
äººç‰©ã®è¡¨æƒ…ã€ãƒãƒ¼ã‚ºã€è¦–ç·šã€è¡£è£…ã®è©³ç´°ã‚’è¨˜è¿°

â–  å…‰ã¨è‰²ã®ç©ºæ°—æ„Ÿ
å…‰ã®å·®ã—æ–¹ï¼ˆé€†å…‰ã€ã‚µã‚¤ãƒ‰å…‰ãªã©ï¼‰ã€è‰²æ¸©åº¦ã€å…¨ä½“ã®ãƒˆãƒ¼ãƒ³ã‚’è¨˜è¿°

â–  èƒŒæ™¯ã¨ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
å ´æ‰€ã®ç‰¹å®šã€å­£ç¯€æ„Ÿã€å‘¨å›²ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¨˜è¿°

â–  ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
ç”»åƒã‹ã‚‰æ„Ÿã˜å–ã‚Œã‚‹ã€Œåˆ‡ãªã•ã€ã€Œå¸Œæœ›ã€ã€Œé™å¯‚ã€ãªã©ã®æŠ½è±¡çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’3ã¤ç¨‹åº¦"""


# =============================================================================
# VisionCore ã‚¯ãƒ©ã‚¹
# =============================================================================

class VisionCore:
    """MiniCPM-V 2.6 int4 ã«ã‚ˆã‚‹ç”»åƒè§£æ"""
    
    def __init__(self, model_id: Optional[str] = None):
        """
        Args:
            model_id: HuggingFaceãƒ¢ãƒ‡ãƒ«IDï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: openbmb/MiniCPM-V-2_6-int4ï¼‰
        """
        self.model_id = model_id or CONFIG["model_id"]
        self.model = None
        self.tokenizer = None
        self._loaded = False
        
    def _load_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’é…å»¶ãƒ­ãƒ¼ãƒ‰"""
        if self._loaded:
            return
        
        # CUDAãƒã‚§ãƒƒã‚¯
        if not torch.cuda.is_available():
            raise RuntimeError("âŒ CUDA is not available! GPU is required for MiniCPM-V inference.")
        
        device_name = torch.cuda.get_device_name(0)
        logger.info(f"ğŸ® GPUæ¤œå‡º: {device_name}")
        logger.info(f"ğŸ”„ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­: {self.model_id}")
        
        from transformers import AutoModel, AutoTokenizer
        
        # int4é‡å­åŒ–ç‰ˆã¯trust_remote_codeãŒå¿…é ˆ
        # device_map="cuda" ã§GPUæ¨è«–ã‚’å¼·åˆ¶
        self.model = AutoModel.from_pretrained(
            self.model_id,
            trust_remote_code=True,
            device_map="cuda",  # ğŸ”§ GPUæ¨è«–ã‚’å¼·åˆ¶
            torch_dtype=torch.float16,  # ğŸ”§ FP16ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        )
        self.model.eval()
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_id,
            trust_remote_code=True,
        )
        
        self._loaded = True
        
        # ãƒ‡ãƒã‚¤ã‚¹ç¢ºèªãƒ­ã‚°
        model_device = next(self.model.parameters()).device
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº† (ãƒ‡ãƒã‚¤ã‚¹: {model_device})")
        
        # VRAMä½¿ç”¨é‡ãƒ­ã‚°
        vram_gb = torch.cuda.memory_allocated() / (1024 ** 3)
        vram_total = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
        logger.info(f"ğŸ“Š VRAMä½¿ç”¨é‡: {vram_gb:.2f} GB / {vram_total:.1f} GB")
    
    def _preprocess_image(self, image_path: str) -> Image.Image:
        """ç”»åƒã®å‰å‡¦ç†ï¼ˆãƒªã‚µã‚¤ã‚ºã§VRAMç¯€ç´„ï¼‰"""
        image = Image.open(image_path).convert("RGB")
        
        # é•·è¾ºã‚’max_image_sizeã«åˆ¶é™
        max_size = CONFIG["max_image_size"]
        w, h = image.size
        
        if max(w, h) > max_size:
            if w > h:
                new_w = max_size
                new_h = int(h * max_size / w)
            else:
                new_h = max_size
                new_w = int(w * max_size / h)
            
            image = image.resize((new_w, new_h), Image.Resampling.LANCZOS)
            logger.info(f"ğŸ“ ç”»åƒãƒªã‚µã‚¤ã‚º: {w}x{h} â†’ {new_w}x{new_h}")
        
        return image
    
    def analyze(self, image_path: str) -> str:
        """
        ç”»åƒã‚’è§£æã—ã€4é …ç›®ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            ç®‡æ¡æ›¸ãå½¢å¼ã®è§£æçµæœ
        """
        # ãƒ¢ãƒ‡ãƒ«ã‚’é…å»¶ãƒ­ãƒ¼ãƒ‰
        self._load_model()
        
        # ç”»åƒå‰å‡¦ç†
        image = self._preprocess_image(image_path)
        
        logger.info(f"ğŸ“¸ ç”»åƒè§£æä¸­: {Path(image_path).name}")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
        msgs = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": [image, USER_PROMPT]},
        ]
        
        # æ¨è«–å®Ÿè¡Œ
        result = self.model.chat(
            image=None,
            msgs=msgs,
            tokenizer=self.tokenizer,
            sampling=True,
            temperature=CONFIG["temperature"],
            top_p=CONFIG["top_p"],
            repetition_penalty=CONFIG["repetition_penalty"],
            max_new_tokens=CONFIG["max_new_tokens"],
        )
        
        # VRAMè§£æ”¾
        self._clear_cache()
        
        logger.info("âœ… è§£æå®Œäº†")
        
        return result
    
    def analyze_simple(self, image_path: str) -> str:
        """
        kotaro_api.pyäº’æ›ã®ã‚·ãƒ³ãƒ—ãƒ«ãªè§£æï¼ˆè¤’ã‚è¦ç´ 3é …ç›®ï¼‰
        V2.1: è¡¨æƒ…ãƒ»ä»•è‰ãƒ»é›°å›²æ°—å„ªå…ˆã€è¡£è£…è‰²ã¯é™¤å¤–
        
        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            JSONå½¢å¼ã®è¤’ã‚è¦ç´ ï¼ˆexpression, gesture, atmosphereï¼‰
        """
        self._load_model()
        image = self._preprocess_image(image_path)
        
        # V2.1ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: è¤’ã‚è¦ç´ ã®ã¿æŠ½å‡ºï¼ˆè¡£è£…è‰²ãƒ»èƒŒæ™¯ç¦æ­¢ï¼‰
        simple_prompt = """ã‚ãªãŸã¯äººç‰©å†™çœŸã®é­…åŠ›ã‚’è¦‹ã¤ã‘ã‚‹ãƒ—ãƒ­ã§ã™ã€‚

ã€ã‚¿ã‚¹ã‚¯ã€‘
ã“ã®å†™çœŸã®äººç‰©ã®ã€Œè¤’ã‚ãŸããªã‚‹ãƒã‚¤ãƒ³ãƒˆã€ã‚’3ã¤æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€æŠ½å‡ºã™ã‚‹é …ç›®ã€‘
1. expression: è¡¨æƒ…ã®é­…åŠ›ï¼ˆä¾‹: ã¯ã«ã‹ã‚“ã ç¬‘é¡”ã€ã‚­ãƒ©ã‚­ãƒ©ã—ãŸç›®ã€å„ªã—ã„å¾®ç¬‘ã¿ï¼‰
2. gesture: ä»•è‰ãƒ»ãƒãƒ¼ã‚ºã®é­…åŠ›ï¼ˆä¾‹: å¯æ„›ã„ãƒ”ãƒ¼ã‚¹ã‚µã‚¤ãƒ³ã€å ‚ã€…ã¨ã—ãŸãƒãƒ¼ã‚ºã€ã‚»ã‚¯ã‚·ãƒ¼ãªç›®ç·šï¼‰
3. atmosphere: å…¨ä½“ã®é›°å›²æ°—ï¼ˆä¾‹: é€æ˜æ„ŸãŒã‚ã‚‹ã€ã‚ªãƒ¼ãƒ©ãŒã™ã”ã„ã€ç™’ã—ç³»ï¼‰

ã€ç¦æ­¢äº‹é …ã€‘
- èƒŒæ™¯ã®èª¬æ˜ã¯çµ¶å¯¾ã«ã—ãªã„
- è¡£è£…ã®è‰²ï¼ˆé’ç³»ã€èµ¤ç³»ã€ç™½ç³»ãªã©ï¼‰ã¯è¨€åŠã—ãªã„
- å›ºæœ‰åè©ãƒ»ãƒ–ãƒ©ãƒ³ãƒ‰åã¯ä½¿ã‚ãªã„
- è‹±èªã¯ä½¿ã‚ãªã„

ã€å‡ºåŠ›å½¢å¼ã€‘JSONå½¢å¼ã§å›ç­”
{"expression": "...", "gesture": "...", "atmosphere": "..."}

æ—¥æœ¬èªã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š"""
        
        msgs = [
            {"role": "user", "content": [image, simple_prompt]},
        ]
        
        result = self.model.chat(
            image=None,
            msgs=msgs,
            tokenizer=self.tokenizer,
            sampling=True,
            temperature=0.2,  # V2.1: ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æŠ‘åˆ¶
            top_p=0.9,        # V2.1: ç¢ºç‡è³ªé‡åˆ¶é™
            max_new_tokens=128,
        )
        
        self._clear_cache()
        
        return result
    
    def analyze_v4(self, image_path: str) -> str:
        """
        V4.2äº’æ›ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°åˆ†æ (A-E + Flags)
        kotaro_api.py ã® call_vlm_analysis_v4 ã¨åŒç­‰ã®ãƒ­ã‚¸ãƒƒã‚¯
        """
        self._load_model()
        image = self._preprocess_image(image_path)

        system_prompt = """# Kotaro VLM Analysis Protocol
## 0. ä½ç½®ã¥ã‘ï¼ˆæœ€ä¸Šä½ï¼‰
æœ¬ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯è™å¤ªéƒã‚¨ãƒ³ã‚¸ãƒ³æœ€ä¸Šä½åˆ¶å¾¡æ–‡æ›¸ã«å¾“ã†æ§‹é€ çš„åˆ†ææŒ‡ç¤ºã§ã‚ã‚‹ã€‚
- æ„Ÿæƒ…ã‚’ç››ã‚‰ãªã„
- æ¨æ¸¬ã—ãªã„
- å®šç¾©æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæ§‹é€ çš„ã«åˆ¤æ–­ã™ã‚‹

## 1. å‡ºåŠ›æ¡ä»¶
- JSONå½¢å¼ã®ã¿ã‚’å‡ºåŠ›
- æŠ½è±¡èªãƒ»é€ƒã’ãƒ¯ãƒ¼ãƒ‰ç¦æ­¢
- èª¬æ˜æ–‡ç¦æ­¢
"""

        user_prompt = """<task>
ç”»åƒã‚’æ§‹é€ çš„ã«åˆ†æã—ã€5è¦ç´ (A-E)ã‚’0-5ã§æ¡ç‚¹ã€ãƒ•ãƒ©ã‚°(flags)ã‚’true/falseã§åˆ¤å®šã›ã‚ˆã€‚
</task>

<scoring_rules>
## æ¡ç‚¹åŸºæº–ï¼ˆ0-5ç‚¹ï¼‰
### A: è¡¨æƒ…ã®ç¢ºå®šé…å»¶ï¼ˆä½™éŸ»ï¼‰
- 0=è¡¨æƒ…å›ºå®š
- 5=ä½™éŸ»ãƒ»æºã‚‰ãã‚ã‚Š

### B: è¦–ç·šã®æ„å›³æœªæ±ºå®šï¼ˆæ§‹å›³ï¼‰
- 0=æ˜ç¢º
- 5=è¦–ç·šãƒ»æ§‹å›³ãŒæ•£ã£ã¦ã„ã‚‹

### C: é¡”ãƒ‘ãƒ¼ãƒ„æ„Ÿæƒ…éåŒæœŸï¼ˆã‚¯ãƒ¼ãƒ«/ã‚®ãƒ£ãƒƒãƒ—ï¼‰
- 0=æ„Ÿæƒ…ä¸€è‡´
- 5=ç›®ã¨å£ã§é•ã†ãƒ»ãƒãƒ¼ã‚ºãŒå¼·ã„

### D: ç·Šå¼µã¨ç·©å’Œã®åŒæ™‚å­˜åœ¨ï¼ˆæ¸©åº¦ï¼‰
- 0=å†·ãŸã„ãƒ»ç·Šå¼µã®ã¿
- 5=æ¸©ã‹ã„ãƒ»ç™’ã‚„ã—ãƒ»å®‰å¿ƒ

### E: è¦ªè¿‘æ„Ÿï¼ˆèº«ä½“æ‰€ä½œãƒã‚¤ãƒ³ãƒˆåˆè¨ˆã€0-15â†’0-5æ­£è¦åŒ–ï¼‰
ä»¥ä¸‹ã®æ‰€ä½œã‚’æ¤œå‡ºã—ã€ãƒã‚¤ãƒ³ãƒˆã‚’åŠ ç®—:
- E01_hand_near_face: é¡”oré ­ä»˜è¿‘ã§æ‰‹ãƒãƒ¼ã‚º â†’ 5ç‚¹
- E02_hand_pose: é¡”ä»¥å¤–ã§æ‰‹ãƒãƒ¼ã‚º â†’ 3ç‚¹
- E03_mouth_open: å£ãŒé–‹ã„ã¦ã„ã‚‹ â†’ 2ç‚¹
- E04_heart_sign: æ‰‹ã§ãƒãƒ¼ãƒˆãƒãƒ¼ã‚¯ â†’ 5ç‚¹
E = round((åˆè¨ˆãƒã‚¤ãƒ³ãƒˆ / 15) * 5)
</scoring_rules>

<flag_rules>
## ãƒ•ãƒ©ã‚°åˆ¤å®šåŸºæº–ï¼ˆtrue/falseï¼‰

### é›°å›²æ°—ãƒ•ãƒ©ã‚°ï¼ˆå³æ ¼åˆ¤å®šï¼‰
- casual_moment: ãµã¨ã—ãŸç¬é–“ã€‚ãŸã ã—pose_safe_theory=trueãªã‚‰åŸºæœ¬false
- nostalgic: ãƒ•ã‚£ãƒ«ãƒ å†™çœŸã®ã‚ˆã†ãªæ€ã„å‡ºæ„Ÿ
- crowd_venue: ã‚¤ãƒ™ãƒ³ãƒˆä¼šå ´ã€äººæ··ã¿ã€ãƒ–ãƒ¼ã‚¹èƒŒæ™¯
- group_feeling: è¤‡æ•°äººã€ã¾ãŸã¯ã€Œä»²é–“ã€ã‚’æ„Ÿã˜ã‚‹

### è¡¨æƒ…ãƒ»ãƒãƒ¼ã‚ºãƒ•ãƒ©ã‚°ï¼ˆå³æ ¼åˆ¤å®šï¼‰
- talk_to: å£ãŒé–‹ã„ã¦ã„ã‚‹ OR æ‰‹ãŒã‚«ãƒ¡ãƒ©æ–¹å‘ OR ç›®ç·šãŒã‚«ãƒ¡ãƒ©ã«åˆºã•ã£ã¦ã„ã‚‹ã€‚ã©ã‚Œã‚‚ç„¡ã‘ã‚Œã°false
- close_dist: ã‚«ãƒ¡ãƒ©ã¨ã®è·é›¢ãŒç‰©ç†çš„ã«ã‹ãªã‚Šè¿‘ã„
- costume_strong: è¡£è£…ã€ã‚³ã‚¹ãƒ—ãƒ¬ã€å½¹ä½œã‚ŠãŒéå¸¸ã«å¼·ã„
- act_point_or_salute: æŒ‡å·®ã—ã€æ•¬ç¤¼ã€æ‰‹ã‚’ä¼¸ã°ã™ãªã©ã®æ˜ç¢ºãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³
- prop_strong: å‚˜ã€çœ‹æ¿ã€é…å¸ƒç‰©ãªã©ã®ã€Œç‰©ã€ãŒç›®ç«‹ã£ã¦ã„ã‚‹

### ä½“ã¨é¡”ã®å‘ãï¼ˆï¼‘ã¤ã®ã¿trueï¼‰
- pose_safe_theory: ä½“ã¯æ–œã‚ã§ã€é¡”ã ã‘ã‚«ãƒ¡ãƒ©ã‚’å‘ã„ã¦ã„ã‚‹ï¼ˆç„¡é›£ãƒ»ã‚»ã‚ªãƒªãƒ¼ï¼‰
- pose_front_true: ä½“ã‚‚é¡”ã‚‚çœŸæ­£é¢ã‚’å‘ã„ã¦ã„ã‚‹ï¼ˆè¦ªå¯†ãƒ»å¼·ï¼‰
- pose_side_cool: ä½“ã¯æ–œã‚ã§ã€é¡”ã‚‚æ–œã‚ã‚„æ¨ªã‚’å‘ã„ã¦ã„ã‚‹ï¼ˆã‚¯ãƒ¼ãƒ«ï¼‰
- pose_front_body_face_angled: ä½“ã¯æ­£é¢ã ãŒã€é¡”ã¯æ–œã‚ã‚’å‘ã„ã¦ã„ã‚‹
</flag_rules>

<output_format>
## å‡ºåŠ›å½¢å¼ï¼ˆå³å®ˆï¼‰
```json
{
    "scores": {"A": 3, "B": 4, "C": 2, "D": 1, "E": 5},
    "flags": {
        "casual_moment": true,
        "nostalgic": false,
        "crowd_venue": false,
        "group_feeling": false,
        "talk_to": true,
        "close_dist": true,
        "costume_strong": false,
        "act_point_or_salute": false,
        "prop_strong": false,
        "pose_safe_theory": true,
        "pose_front_true": false,
        "pose_side_cool": false,
        "pose_front_body_face_angled": false
    }
}
```
</output_format>

## Final Output
"""
        msgs = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": [image, user_prompt]},
        ]

        result = self.model.chat(
            image=None,
            msgs=msgs,
            tokenizer=self.tokenizer,
            sampling=True,
            temperature=0.3,
            max_tokens=512,
        )

        self._clear_cache()
        return result

    def _clear_cache(self):
        """VRAMè§£æ”¾"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            logger.debug("ğŸ§¹ VRAM ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢")
    
    def unload(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦VRAMã‚’å®Œå…¨è§£æ”¾"""
        if self._loaded:
            del self.model
            del self.tokenizer
            self.model = None
            self.tokenizer = None
            self._loaded = False
            
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            logger.info("ğŸ”Œ ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")


# =============================================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
# =============================================================================

_vision_core_instance: Optional[VisionCore] = None


def get_vision_core() -> VisionCore:
    """ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _vision_core_instance
    if _vision_core_instance is None:
        _vision_core_instance = VisionCore()
    return _vision_core_instance


def analyze_image_minicpm(image_path: str) -> str:
    """
    kotaro_api.py ã‹ã‚‰ã®å‘¼ã³å‡ºã—ç”¨é–¢æ•°
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        ç”»åƒè§£æçµæœï¼ˆ3é …ç›®ï¼‰
    """
    vision = get_vision_core()
    return vision.analyze_simple(image_path)


# =============================================================================
# CLI ãƒ†ã‚¹ãƒˆ
# =============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="MiniCPM-V 2.6 Vision Core")
    parser.add_argument("--image", type=str, required=True, help="ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--mode", type=str, default="simple", choices=["simple", "full"],
                        help="è§£æãƒ¢ãƒ¼ãƒ‰: simple=3é …ç›®, full=4é …ç›®è©³ç´°")
    
    args = parser.parse_args()
    
    print("\n" + "=" * 60)
    print("ğŸ‘ï¸  MiniCPM-V 2.6 Vision Core")
    print("=" * 60)
    
    vision = VisionCore()
    
    if args.mode == "full":
        result = vision.analyze(args.image)
    else:
        result = vision.analyze_simple(args.image)
    
    print("\nğŸ“‹ è§£æçµæœ:")
    print("-" * 40)
    print(result)
    print("-" * 40)
    
    vision.unload()
    print("=" * 60 + "\n")
